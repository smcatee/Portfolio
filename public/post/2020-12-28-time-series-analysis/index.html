<script src="index_files/header-attrs-2.6/header-attrs.js"></script>


<p></br></p>
<p>This document shows a brief temperature time series analysis using three NOAA quality control datasets. This analysis functions as proof and practice for concepts that will be employed on more complex temperature time-series data. While researching analytical techniques and working through issues during analysis it became apparent that time-series temperature data requires special consideration in a few key aspects. Namely, distribution and seasonality. The discovery and treatment for those aspects is presented below.</p>
<p></br><br />
</br></p>
<hr />
<div id="data-selection" class="section level2">
<h2>Data Selection</h2>
<p>Weather station data were downloaded from <a href="https://www.ncdc.noaa.gov/crn/qcdatasets.html" class="uri">https://www.ncdc.noaa.gov/crn/qcdatasets.html</a></p>
<p>Three weather stations were picked for this analysis, two of which are in the same town while the third is in a different state. The assumption is that the two nearby stations will record similar temperature patterns while the distant station will record a significantly different temperature pattern.</p>
<p>Durham, North Carolina weather station data from the two stations labeled ‘N’ and ‘SSW’ were chosen for the years 2017 to 2020. Data from the distant station in Manhattan, Kansas were gathered for the same years. The columns containing date, local time, and temperature were selected for each location.</p>
<p>The main statistical tool will be pairwise correlation between weather stations. There are some assumptions that will be checked first to determine the proper correlation method to use. Following the correlation test the data will be deseasonalized and explored to help inform future directions of analysis.</p>
<p></br><br />
</br></p>
<hr />
</div>
<div id="packages-used" class="section level2">
<h2>Packages Used</h2>
<pre class="r"><code>library(readr); library(magrittr); library(plotly);
library(chron); library(dplyr); library(tidyr);
library(tibble)</code></pre>
<p></br><br />
</br></p>
<hr />
</div>
<div id="loading-data" class="section level2">
<h2>Loading Data</h2>
<p>The data were parsed as follows, for all years listed.</p>
<pre class="r"><code>colNames &lt;- readr::read_delim(&quot;/path/to/ColNames.txt&quot;, delim = &quot; &quot;, col_names = FALSE) %&gt;% unlist()
durhamN2017 &lt;- readr::read_delim( &quot;/path/to/CRNH0203-2017-NH_Durham_2_N.txt&quot;,
  delim = &quot; &quot;, col_names = durhamColNames) %&gt;% dplyr::select(LST_DATE, LST_TIME, T_CALC)
durhamSSW2017 &lt;- readr::read_delim( &quot;/path/to/CRNH0203-2017-NH_Durham_2_SSW.txt&quot;,
  delim = &quot; &quot;, col_names = durhamColNames) %&gt;% dplyr::select(LST_DATE, LST_TIME, T_CALC)
manhattan2017 &lt;- readr::read_delim( &quot;/path/to/CRNH0203-2017-KS_Manhattan_6_SSW.txt&quot;,
  delim = &quot; &quot;, col_names = durhamColNames) %&gt;% dplyr::select(LST_DATE, LST_TIME, T_CALC)</code></pre>
<p></br><br />
</br></p>
<hr />
</div>
<div id="cleaning" class="section level2">
<h2>Cleaning</h2>
<p>The loaded data were combined and cleaned. The code chunk below shows all steps taken, with limited explanations for each step. Check out “Cleaning Data” to find some useful cleaning, visualizing and generating steps on a particularly messy(realistic) dataset.</p>
<pre class="r"><code>durhamN &lt;- rbind(durhamN2017,durhamN2018, durhamN2019, durhamN2020)
durhamSSW &lt;- rbind(durhamSSW2017, durhamSSW2018, durhamSSW2019, durhamSSW2020)
manhattan &lt;- rbind(manhattan2017, manhattan2018, manhattan2019, manhattan2020)

durhamN$T_CALC %&lt;&gt;% as.numeric()
durhamSSW$T_CALC %&lt;&gt;% as.numeric()
manhattan$T_CALC %&lt;&gt;% as.numeric()

# find the number that is used as NA value
durhamSSW$T_CALC %&gt;% unique() %&gt;% sort()

durhamN$T_CALC[durhamN$T_CALC == -9999] &lt;- NA
durhamSSW$T_CALC[durhamSSW$T_CALC == -9999] &lt;- NA
manhattan$T_CALC[manhattan$T_CALC == -9999] &lt;- NA

# Convert dates and times to chron format
durhamSSW$LST_DATE &lt;- as.dates(as.character(durhamSSW$LST_DATE), format = &quot;ymd&quot;)
durhamN$LST_DATE &lt;- as.dates(as.character(durhamN$LST_DATE), format = &quot;ymd&quot;)
manhattan$LST_DATE &lt;- as.dates(as.character(manhattan$LST_DATE), format = &quot;ymd&quot;)

durhamSSW$LST_TIME %&lt;&gt;% as.character() %&gt;% strtrim(2) %&gt;% paste0(&quot;:&quot;,&quot;00:00&quot;) %&gt;% as.times()
durhamN$LST_TIME %&lt;&gt;% as.character() %&gt;% strtrim(2) %&gt;% paste0(&quot;:&quot;,&quot;00:00&quot;) %&gt;% as.times()
manhattan$LST_TIME %&lt;&gt;% as.character() %&gt;% strtrim(2) %&gt;% paste0(&quot;:&quot;,&quot;00:00&quot;) %&gt;% as.times()

# Combine durham tables
durhamTemps &lt;- full_join(x = durhamSSW, y = durhamN, by = c(&quot;LST_DATE&quot;, &quot;LST_TIME&quot;))
allTemps &lt;- full_join(x = durhamTemps, y = manhattan, by = c(&quot;LST_DATE&quot;, &quot;LST_TIME&quot;))
# last row is weird, take it out
allTemps &lt;- allTemps[-nrow(allTemps),]

colnames(allTemps) &lt;- c(&quot;Date&quot;, &quot;Time&quot;, &quot;DurhamSSW&quot;, &quot;DurhamN&quot;, &quot;Manhattan&quot;)

#pivot longer for plotting
allTemps &lt;- pivot_longer(allTemps, cols = 3:5, names_to = &quot;Location&quot;, values_to = &quot;Temperature&quot;)</code></pre>
<p></br><br />
</br></p>
<hr />
</div>
<div id="exploring-data-seasonality" class="section level2">
<h2>Exploring Data Seasonality</h2>
<p>The data is now cleaned and the analysis workflow can start. First a few plots will be generated to get a sense for the data and to view its seasonality.</p>
<pre class="r"><code>#daily
ggplot(allTemps[allTemps$Location == &quot;Manhattan&quot;,],
       aes(x=Time %&gt;% as.character() %&gt;% substr(0,2), y=Temperature)) +
  geom_boxplot() +
  theme(axis.title.x=element_blank(), axis.ticks.x=element_blank(), axis.ticks.y=element_blank()) +
  ylab(&quot;ºC&quot;)

#monthly
ggplot(allTemps[allTemps$Location == &quot;Manhattan&quot;,],
       aes(x=Date %&gt;% chron::dates() %&gt;% months() %&gt;% factor(), y=Temperature)) +
  geom_boxplot() +
  theme(axis.title.x=element_blank(),axis.ticks.x=element_blank(), axis.ticks.y=element_blank()) +
  ylab(&quot;ºC&quot;)

#yearly
ggplot(allTemps[allTemps$Location == &quot;Manhattan&quot;,],
       aes(x=Date %&gt;% years() %&gt;% factor(), y=Temperature)) + xlab(&quot;Time&quot;) +
  geom_boxplot() + theme(axis.ticks.x=element_blank(), axis.ticks.y=element_blank()) +
  ylab(&quot;ºC&quot;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-5"></span>
<img src="index_files/figure-html/unnamed-chunk-5-1.png" alt="Figure: Temperature quartiles displayed over the intervals: 24 hours, 12 months, 5 years." width="576" /><img src="index_files/figure-html/unnamed-chunk-5-2.png" alt="Figure: Temperature quartiles displayed over the intervals: 24 hours, 12 months, 5 years." width="576" /><img src="index_files/figure-html/unnamed-chunk-5-3.png" alt="Figure: Temperature quartiles displayed over the intervals: 24 hours, 12 months, 5 years." width="576" />
<p class="caption">
Figure 1: Figure: Temperature quartiles displayed over the intervals: 24 hours, 12 months, 5 years.
</p>
</div>
<p></br></p>
<p>Interestingly, there are a few data points from 2016 in this set. Also, it is apparent that there is a yearly and daily seasonal trend, and no obvious trend over the years. The seasonality should not affect correlation, so that will not be explored until later.</p>
<p></br><br />
</br></p>
<hr />
</div>
<div id="tukeys-five-numbers" class="section level2">
<h2>Tukey’s Five Numbers</h2>
<p>Some quick statistics can roughly compare the temperature datasets to each other. Tukey’s Five Numbers can give a sense of the temperature distribution at each location.</p>
<pre class="r"><code>TFNtxt &lt;- &quot;Tukey&#39;s Five Numbers &quot;
paste(TFNtxt, &quot;DurhamN&quot;,
      paste(fivenum(allTemps$Temperature[allTemps$Location == &quot;DurhamN&quot;]),collapse=&quot; &quot;))
paste(TFNtxt, &quot;DurhamSSW&quot;,
      paste(fivenum(allTemps$Temperature[allTemps$Location == &quot;DurhamSSW&quot;]),collapse=&quot; &quot;))
paste(TFNtxt, &quot;Manhattan&quot;,
      paste(fivenum(allTemps$Temperature[allTemps$Location == &quot;Manhattan&quot;]),collapse=&quot; &quot;))</code></pre>
<pre><code>## [1] &quot;Tukey&#39;s Five Numbers  DurhamN -24.5 0.8 9.1 17.8 34.7&quot;
## [1] &quot;Tukey&#39;s Five Numbers  DurhamSSW -24.6 0.7 9 17.7 34.9&quot;
## [1] &quot;Tukey&#39;s Five Numbers  Manhattan -22.8 4.1 14.3 22.9 40.5&quot;</code></pre>
<p></br></p>
<p>All stations have similar high/low values, but there is a noticeable difference in the quartiles for the Manhattan station. The two Durham stations on the other hand are highly similar.</p>
<p></br><br />
</br></p>
<hr />
</div>
<div id="test-normality" class="section level2">
<h2>Test Normality</h2>
<p>Correlation lends its self well for comparing time-series temperature data. The Pearson correlation would be the first choice since it is not only the most widely used, but it is also faster, O(n), than the rank based methods that sort data, O(nlogn), before correlating it.<br />
To run a Pearson correlation with a clean conscience the data must be checked for normality. A visual check for normality can be done with a QQ plot and a density plot.</p>
<pre class="r"><code># QQ plot of all temp sets
ggplot(allTemps, aes(sample=Temperature)) +
  geom_qq_line() +
  geom_qq(aes(colour=Location),alpha=0.3,size=0.6) + ylim(-35, 35) + scale_colour_grey() +
  theme(axis.text=element_text(size=12),
        axis.ticks.x=element_blank(),
        axis.ticks.y=element_blank()) +
  xlab(&quot;Theoretical&quot;) + ylab(&quot;Samples&quot;) + ggtitle(&quot;QQ Plot&quot;)

# density plot of all temp sets
ggplot(allTemps, aes(x=Temperature)) +
  geom_density(aes(color=Location), size=0.6) + scale_colour_grey() +
  theme(axis.text=element_text(size=12),
        axis.ticks.x=element_blank(),
        axis.ticks.y=element_blank()) + 
  xlab(&quot;ºC&quot;) + ggtitle(&quot;Density Plot&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-7-1.png" width="50%" /><img src="index_files/figure-html/unnamed-chunk-7-2.png" width="50%" />
</br></p>
<p>The QQ plot does not look perfectly normal for each location, also the density plot shows multiple peaks. A Shapiro-Wilk test can provide a more thorough follow-up.</p>
<pre class="r"><code>#shaprio.test() can only take up to 5000 values; there are 32806 values per location
randsampleDurhamN &lt;- filter(allTemps,
                            Location == &quot;DurhamN&quot;)[sample(1:32806, 5000, replace=FALSE),]
randsampleDurhamSSW &lt;- filter(allTemps,
                              Location == &quot;DurhamSSW&quot;)[sample(1:32806, 5000, replace=FALSE),]
randsampleManhattan &lt;- filter(allTemps,
                              Location == &quot;Manhattan&quot;)[sample(1:32806, 5000, replace=FALSE),]

swTestDurhamN &lt;- randsampleDurhamN %&gt;%
  dplyr::select(Temperature) %&gt;% unlist() %&gt;% shapiro.test()

swTestDurhamSSW &lt;- randsampleDurhamSSW %&gt;%
  dplyr::select(Temperature) %&gt;% unlist() %&gt;% shapiro.test()

swTestManhattan &lt;- randsampleManhattan %&gt;%
  dplyr::select(Temperature) %&gt;% unlist() %&gt;% shapiro.test()

paste(&quot;DurhamN   -- W-stat:&quot;,
      round(swTestDurhamN$statistic,4),
      &quot;   p-value:&quot; ,
      swTestDurhamN$p.value)

paste(&quot;DurhamSSW -- W-stat:&quot;,
      round(swTestDurhamSSW$statistic,4),
      &quot;   p-value:&quot; ,
      swTestDurhamSSW$p.value)

paste(&quot;Manhattan -- W-stat:&quot;,
      round(swTestManhattan$statistic,4),
      &quot;   p-value:&quot; ,
      swTestManhattan$p.value)</code></pre>
<pre><code>## [1] &quot;DurhamN   -- W-stat: 0.9871    p-value: 9.66354939096328e-21&quot;
## [1] &quot;DurhamSSW -- W-stat: 0.9868    p-value: 3.48098589570404e-21&quot;
## [1] &quot;Manhattan -- W-stat: 0.9787    p-value: 9.72604246249421e-27&quot;</code></pre>
<p></br></p>
<p>For all three temperature datasets the Shapiro-Wilk null hypothesis is rejected, so none of the datasets are normally distributed. A Pearson correlation, therefore, can not be used for comparison. A non-parametric correlation test can be used instead of the Pearson correlation.</p>
<p></br><br />
</br></p>
<hr />
</div>
<div id="correlation" class="section level2">
<h2>Correlation</h2>
<p>In this case a Kendall’s Tau correlation will be used.</p>
<pre class="r"><code>ktCorDurhamNDurhamSSW &lt;- cor.test(allTemps$Temperature[allTemps$Location == &quot;DurhamN&quot;], 
         allTemps$Temperature[allTemps$Location == &quot;DurhamSSW&quot;], 
         use = &quot;pairwise.complete.obs&quot;, method = &quot;kendall&quot;)
ktCorDurhamNManhattan &lt;- cor.test(allTemps$Temperature[allTemps$Location == &quot;DurhamN&quot;], 
         allTemps$Temperature[allTemps$Location == &quot;Manhattan&quot;], 
         use = &quot;pairwise.complete.obs&quot;, method = &quot;kendall&quot;)
ktCorDurhamSSWManhattan &lt;- cor.test(allTemps$Temperature[allTemps$Location == &quot;DurhamSSW&quot;], 
         allTemps$Temperature[allTemps$Location == &quot;Manhattan&quot;], 
         use = &quot;pairwise.complete.obs&quot;, method = &quot;kendall&quot;)

prntTxt &lt;- c(&quot;  -- kt-cor:&quot;,&quot;    z-stat:&quot;,&quot;    p-val:&quot;)
paste(&quot;DurhamN &amp; DurhamSSW&quot;,prntTxt[1], round(ktCorDurhamNDurhamSSW$estimate,4), prntTxt[2],
      round(ktCorDurhamNDurhamSSW$statistic,4), prntTxt[3], ktCorDurhamNDurhamSSW$p.value)
paste(&quot;DurhamN &amp; Manhattan&quot;,prntTxt[1], round(ktCorDurhamNManhattan$estimate,4), prntTxt[2],
      round(ktCorDurhamNManhattan$statistic,4), prntTxt[3], ktCorDurhamNManhattan$p.value)
paste(&quot;DurhamSSW &amp; Manhattan&quot;,prntTxt[1], round(ktCorDurhamSSWManhattan$estimate,4), prntTxt[2],
      round(ktCorDurhamSSWManhattan$statistic,4), prntTxt[3], ktCorDurhamSSWManhattan$p.value)</code></pre>
<pre><code>## [1] &quot;DurhamN &amp; DurhamSSW   -- kt-cor: 0.9682     z-stat: 259.4059     p-val: 0&quot;
## [1] &quot;DurhamN &amp; Manhattan   -- kt-cor: 0.5916     z-stat: 158.5514     p-val: 0&quot;
## [1] &quot;DurhamSSW &amp; Manhattan   -- kt-cor: 0.5854     z-stat: 157.9489     p-val: 0&quot;</code></pre>
<p></br></p>
<p>The two Durham stations have a strong correlation to each other (0.9682) while the correlations between the Manhattan station and the two Durham stations is moderate, around 0.5885</p>
<p></br><br />
</br></p>
<hr />
</div>
<div id="explore-temperature-distributions" class="section level2">
<h2>Explore Temperature Distributions</h2>
<p>The QQ and density plots as well as the Kendall’s Tau test indicate that the Manhattan dataset has a different distribution than the Durham sets. A simple way to compare two sets with different distributions is to plot their difference.</p>
<pre class="r"><code>manhattanDurhamNDifference &lt;- allTemps$Temperature[allTemps$Location == &quot;Manhattan&quot;] -
  allTemps$Temperature[allTemps$Location == &quot;DurhamN&quot;]
hist(manhattanDurhamNDifference, xlab = &quot;ºC&quot;, main=&quot;Manhattan and Durham N temperature difference&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-10-1.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code>fivenum(manhattanDurhamNDifference)</code></pre>
<pre><code>## [1] -26.2  -0.3   4.6   9.1  32.2</code></pre>
<p></br></p>
<p>The average temperature from 2017 to 2020 in Manhattan, Kansas is about 4.6 degrees higher than Durham, North Carolina ‘N’. It is interesting to note that about 50% of the temperature variation is only ±5ºC around the mean, however the range of outliers is a massive ±30ºC.<br />
It is possible to further explore the variation in temperature at each location by removing seasonality.</p>
<p></br><br />
</br></p>
<hr />
</div>
<div id="deseasonalize" class="section level2">
<h2>Deseasonalize</h2>
<p>The yearly and daily seasonal effects are apparent when viewing this data in the first few plots. It is possible to view only the daily temperature distribution around the mean for that day. This is done by removing daily seasonality from the data.</p>
<p>First, daily seasonality is removed using a moving average filter. This leaves the yearly seasonality and the residuals.</p>
<pre class="r"><code>dayTrendManhattan &lt;- stats::filter(allTemps$Temperature[allTemps$Location == &quot;Manhattan&quot;],
       filter=c(1/2, rep(1, times=23), 1/2)/24,
       method=&quot;convo&quot;,
       sides=2)

#daily seasonality removed
plot(dayTrendManhattan, xlab=&quot;Hours since 12/31/2016 20:00:00&quot;, ylab=&quot;ºC&quot;, main=&quot;Daily Temperature Average&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-11-1.png" width="576" style="display: block; margin: auto;" />
</br></p>
<p>Now it is a simple task to remove the daily seasonal trend by simply subtracting it out of the original time-series. Once that is done a few plots and statistics can dig into the daily temperature distribution.</p>
<pre class="r"><code>daySeasonEffManhattan &lt;- allTemps$Temperature[allTemps$Location == &quot;Manhattan&quot;] - dayTrendManhattan

plot(daySeasonEffManhattan, xlab=&quot;Hours since 12/31/2016 20:00:00&quot;, ylab=&quot;ºC&quot;, main=&quot;Deseasonalized Daily Temperature&quot;)
hist(daySeasonEffManhattan, xlab=&quot;ºC&quot;, main=&quot;Daily Temperature Distribution&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-12-1.png" width="50%" /><img src="index_files/figure-html/unnamed-chunk-12-2.png" width="50%" /></p>
<pre class="r"><code>#There is only one outlier below -13 from the daily mean
paste(&quot;Outliers below -12ºC:  &quot;,
      paste(round(daySeasonEffManhattan[daySeasonEffManhattan &lt; -12 &amp; !is.na(daySeasonEffManhattan)],2),
            collapse=&quot; &quot;))
paste(TFNtxt, paste(fivenum(daySeasonEffManhattan) %&gt;% round(4), collapse=&quot; &quot;))</code></pre>
<pre><code>## [1] &quot;Outliers below -12ºC:   -12.45 -12.09 -20.8&quot;
## [1] &quot;Tukey&#39;s Five Numbers  -20.8 -2.6875 -0.4396 2.7479 13.1229&quot;</code></pre>
<p></br></p>
<p>The three locations can be deseasonalized and roughly compared using Tukey’s Five Numbers.</p>
<pre class="r"><code>daySeasonEffDurhamN &lt;- allTemps$Temperature[allTemps$Location == &quot;DurhamN&quot;] - 
  stats::filter(allTemps$Temperature[allTemps$Location == &quot;DurhamN&quot;],
                filter=c(1/2, rep(1, times=23), 1/2)/24, method=&quot;convo&quot;, sides=2)

daySeasonEffDurhamSSW &lt;- allTemps$Temperature[allTemps$Location == &quot;DurhamSSW&quot;] - 
  stats::filter(allTemps$Temperature[allTemps$Location == &quot;DurhamSSW&quot;],
                filter=c(1/2, rep(1, times=23), 1/2)/24, method=&quot;convo&quot;, sides=2)

paste(TFNtxt,&quot;DurhamN&quot;,paste(fivenum(daySeasonEffDurhamN)  %&gt;% round(4),collapse=&quot; &quot;))
paste(TFNtxt,&quot;DurhamSSW&quot;,paste(fivenum(daySeasonEffDurhamSSW) %&gt;% round(4),collapse=&quot; &quot;))
paste(TFNtxt,&quot;Manhattan&quot;,paste(fivenum(daySeasonEffManhattan) %&gt;% round(4),collapse=&quot; &quot;))</code></pre>
<pre><code>## [1] &quot;Tukey&#39;s Five Numbers  DurhamN -11.2375 -2.2458 -0.2812 2.2979 11.6583&quot;
## [1] &quot;Tukey&#39;s Five Numbers  DurhamSSW -11.3646 -2.3354 -0.2729 2.4354 11.9917&quot;
## [1] &quot;Tukey&#39;s Five Numbers  Manhattan -20.8 -2.6875 -0.4396 2.7479 13.1229&quot;</code></pre>
<p></br></p>
<p>Each location appears to have similar daily temperature distributions, however Manhattan has slightly narrower distributions than Durham. There is also an outlier in the Manhattan set, since this outlier was not present before it may be due to a calculation error when removing seasonality.</p>
<p></br><br />
</br></p>
<hr />
</div>
<div id="daily-temperature-distribution" class="section level2">
<h2>Daily Temperature Distribution</h2>
<p>Quartiles for the distributions of daily temperatures around the mean can be viewed over the period of a year in the same way that the hourly temperature was viewed at the beginning of this document.</p>
<pre class="r"><code>dailyTempDistributionDurhamN &lt;- ggplot(
  add_column(allTemps[allTemps$Location == &quot;DurhamN&quot;,], dailySeasonalEffect = daySeasonEffDurhamN),
  aes(x=Date %&gt;% chron::dates() %&gt;% months() %&gt;% factor(),y=dailySeasonalEffect)) +
  geom_boxplot() + theme(axis.title.x=element_blank(),axis.text.x=element_blank(),axis.ticks.x=element_blank()) +
  ylab(&quot;Daily temp distributions&quot;)

dailyTempDistributionDurhamSSW &lt;- ggplot(
  add_column(allTemps[allTemps$Location == &quot;DurhamSSW&quot;,], dailySeasonalEffect = daySeasonEffDurhamSSW),
  aes(x=Date %&gt;% chron::dates() %&gt;% months() %&gt;% factor(),y=dailySeasonalEffect)) +
  geom_boxplot() + theme(axis.title.x=element_blank(),axis.text.x=element_blank(),axis.ticks.x=element_blank()) +
  ylab(&quot;Daily temp distributions&quot;)

dailyTempDistributionManhattan &lt;- ggplot(
  add_column(allTemps[allTemps$Location == &quot;Manhattan&quot;,], dailySeasonalEffect = daySeasonEffManhattan),
  aes(x=Date %&gt;% chron::dates() %&gt;% months() %&gt;% factor(),y=dailySeasonalEffect)) +
  geom_boxplot() + xlab(&quot;Time&quot;) + ylab(&quot;Daily temp distributions&quot;)

dailyTempDistributionDurhamN
dailyTempDistributionDurhamSSW
dailyTempDistributionManhattan</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-15-1.png" width="576" style="display: block; margin: auto;" /><img src="index_files/figure-html/unnamed-chunk-15-2.png" width="576" style="display: block; margin: auto;" /><img src="index_files/figure-html/unnamed-chunk-15-3.png" width="576" style="display: block; margin: auto;" />
</br></p>
<p>It appears that the distribution of daily temperatures does change over the period of a year. This is useful information to know for any further analysis of temperature time-series datasets. It is also interesting to note that the distribution of Manhattan temperatures is narrower than the Durham distributions for every month.</p>
<p></br><br />
</br></p>
<hr />
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>Through this exploration and analysis a few key takeaways were discovered about the three temperature datasets. Importantly, it was discovered that this temperature data does not follow a normal distribution according to the Shapiro-Wilk test. Taking this into consideration the three datasets were measured for correlation using the Kendall’s Tau method. This correlation test showed that the two Durham weather stations had recorded highly correlated temperature readings, while the Manhattan weather station was only moderately correlated to the two Durham stations. Comparing the difference of the ‘N’ Durham station to the Manhattan station it was learned that Manhattan has a higher average temperature, but narrower distribution, than Durham. Further steps that removed seasonality showed that there is a shift in daily temperature distributions through the year. Namely, a wider distribution around the summer and a narrower distribution around the winter.</p>
<p></br><br />
</br></p>
<hr />
</div>
<div id="next-steps" class="section level2">
<h2>Next Steps</h2>
<p>This brief analysis can open many doors for further investigation. One of the most important would be determining if this, or any, temperature data can fit a distribution function. Since there are two seasonality components in this data, there could be a combination of distributions at play.</p>
<p>Temperature swings from day to night is an ecologically important stress factor. If this analysis is used for later work to compare biological stress factors at different locations, then a special analysis of temperature ranges and rates of change would be useful.</p>
<p></br><br />
</br></p>
<hr />
</div>
<div id="sources-of-inspiration-ideas-and-facts" class="section level2">
<h2>Sources of inspiration, ideas, and facts</h2>
<p>Like a good R-user, I always <a href="https://www.rdocumentation.org/">Read The Manual</a> first.<br />
–Time-series concepts and analysis:<br />
qq plot and concepts <a href="https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/wea.2158" class="uri">https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/wea.2158</a><br />
decomposition and much much more <a href="https://nwfsc-timeseries.github.io/atsa-labs/sec-tslab-decomposition-of-time-series.html" class="uri">https://nwfsc-timeseries.github.io/atsa-labs/sec-tslab-decomposition-of-time-series.html</a><br />
correlation algorithm time complexity <a href="https://arxiv.org/pdf/1712.01521.pdf" class="uri">https://arxiv.org/pdf/1712.01521.pdf</a><br />
–Rmd use and styling<br />
styling ideas <a href="https://holtzy.github.io/Pimp-my-rmd/" class="uri">https://holtzy.github.io/Pimp-my-rmd/</a><br />
pre-loaded themes <a href="https://www.datadreaming.org/post/r-markdown-theme-gallery/" class="uri">https://www.datadreaming.org/post/r-markdown-theme-gallery/</a><br />
pre-loaded syntax highlighting <a href="https://www.garrickadenbuie.com/blog/pandoc-syntax-highlighting-examples/" class="uri">https://www.garrickadenbuie.com/blog/pandoc-syntax-highlighting-examples/</a></p>
</div>
