---
title: Exploring PubMed Abstracts with Spark
author: Sean D McAtee
date: '2021-03-07'
slug: exploring-pubmed-abstracts-with-spark
categories: []
tags: []
Description: 'TF-IDF of Abstract text to explore Journal titles'
Tags: []
Categories: []
DisableComments: no
---

</br>

## Motivation: 

Biomedical research is performed at a remarkable pace. Many stakeholders benefit from 
the advance of this research, however the volume of literature in various Biomedical subjects
is increasingly becoming a hurdle for researchers and practitioners. Valuable time is
spent in literature review, searching for relevant literature and extracting useful
information from it. There are many tools for semi automated literature search and
review, including information extraction.

The number of academic journals is also potenially overwhelming.
Some journals have massively broad subjects and wide circulation, while others may be
niche journals with smaller readerships. Subject matter is difficult to determine based
on a cursory glance at the title and a few published articles. Therefore it could be
useful to classify journals based on the literature that they publish.

</br>

The PubMed database of article metadata is an XML structured mass of information containing the titles, authors, abstracts, affiliations and many other potentially useful fields. 

I used TF-IDF feature vectors to examine academic journals using abstracts on PubMed. The distributed computing environment, Spark, is used to filter and transform text into TF-IDF vectors.

</br></br>

## Datasets

This analysis uses PubMed metadata to compare subgroups of journals. The data was
downloaded from the PubMed Baseline at ftp://ftp.ncbi.nlm.nih.gov/pubmed/baseline.
This data contains many fields for each article hosted on PubMed. The fields used
in the analysis below were 'PMID', 'AbstractText', and 'JournalTitle'.  
The downloaded metadata was loaded as XML into the NYU HPC distributed file
system (HDFS). The spark-xml package from Databricks was used to parse the XML
files into a Spark DataFrame. As a DataFrame the metadata was filtered and
transformed into word feature vectors for every journal listed.


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(magrittr); library(readr); library(glue); library(dplyr); library(tidyr)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
workingDir <- 
  "C:/Users/seand/OneDrive/Documents/Class_Docs/RBDA_project_data/diabetes_asthma_hiv/"

asthma <- read_csv(glue("{workingDir}asthmaAll.csv"),
                   col_names = c("journal_x", "journal_asthma", "cosine_similarity"))

diabetes <- read_csv(glue("{workingDir}diabetesAll.csv"),
                   col_names = c("journal_x", "journal_diabetes", "cosine_similarity"))

hiv <- read_csv(glue("{workingDir}hivAll.csv"),
                   col_names = c("journal_x", "journal_hiv", "cosine_similarity"))
```

</br>

Three hand selected subgroups of journals were compared to the whole corpus: Diabetes, Asthma, and HIV. Journals were selected for each group if their title contained the disease term. I was curious to find out what journals had similar TF-IDF feature vectors to these highly specific groups of journals.

```{r}
asthma$journal_asthma %>% unique() %>% head(3)
diabetes$journal_diabetes %>% unique() %>% head(3)
hiv$journal_hiv %>% unique() %>% head(3)
```

</br></br>

The sizes of the hand-selected groups compared to the whole set of journals:

```{r eval=FALSE}
list(
  distinct_all = n_distinct(asthma$journal_x),
  distinct_asthma = n_distinct(asthma$journal_asthma),
  distinct_diabetes = n_distinct(diabetes$journal_diabetes),
  distinct_hiv = n_distinct(hiv$journal_hiv)
  ) %>% as.data.frame( row.names = "n_journals")
```

</br></br>


Spark is used to filter and transform the abstracts into feature vectors
for each academic journal. These journals are then compared to each other. Three subgroups
are filtered from the whole set. Each subgroup reflects a sample of journals in different
health subjects: Diabetes, Asthma, and HIV. These three subgroups are then compared to the
whole set of feature vectors. The cosine similarity is calculated for all comparisons,
and each subgroup's distribution from 0 (no similarities) to 1 (identical) is assessed.


</br></br>

## Design

</br>

### Lemma Array Generation

Data was cleaned, analyzed, and visualized in Spark and R. After data collection
and XML parsing, the Spark DataFrame was selected for "PMID", "AbstractText", and
"JournalTitle" columns. The Stanford CoreNLP package was used to split sentences
in each AbstractText string into word arrays, and
convert words into generic lemmas. Part of speech tags were generated for each
lemma to filter out uninformative elements, such as coordinating conjunctions
and prepositions. Once filtered, the lemmas were aggregated into an array for each
JournalTitle. This resulted in all unique JournalTitle having a corresponding
array of lemmas from all articles in this PubMed sample. At this stage there were
5591 unique JournalTitles and 112,405 unique lemmas across all JournalTitles.  

</br></br>

## TF-IDF Features

Lemma arrays were converted to TF-IDF feature vectors in the following way. The Spark
ML package was used to hash lemmas. The number of features for the hash function 
was set above 5591 to $2^17$ to avoid collisions and to increase calculation speed.
Spark ML was also used to calculate IDF for the hashed lemma vectors. IDF values were
rescaled to generate TF-IDF values.

</br></br>

## Pairwise Cosine Similarity

$$
cos(\pmb x, \pmb y) = \frac {\pmb x \cdot \pmb y}{||\pmb x|| \cdot ||\pmb y||}(A * B)/(||A||||B||)
$$

$\frac{a}{b}$


Subgroups of journal titles were selected based three health terms: Diabetes, HIV, and
Asthma. This was done in order to gather three groups for cosine similarity analysis.
The subgroups were selected using RegEx pattern matching. Each group was passed to
the pairwise cosine similarity user-defined-function to be compared against the
whole set. Each cosine similarity DataFrame was written to csv files for further
analysis in R.



[Top rows of the Spark DataFrame containing part]()

</br></br>

## Quantile Comparisons

The final analysis and visualization steps were completed in R. Each 10th quantile
was calculated for each set using stats::quantile(). The distributions of
each set is concentrated towards 0 with long tails trailing towards 1. This is
due to the fact that the cosine similarity of most JournalTitle feature vectors
are not similar. A thin distribution tail contains the relatively few feature
vectors that are similar. Quantiles were also calculated for isolated subgroups
to determine if the pattern matching technique yielded groups that were internally
more similar than the whole corpus. Internally, the groups had less spread than the
whole corpus according to quantile calculations.

</br></br>

#### Within Group Similarity Quantiles

```{r table, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
tabl = "
| Subgroup | 10 | 20 | 30 | 40 | 50 | 60 | 70 | 80 | 90 |
| ---- |  ----: |  ----: |  ----: |  ----: |  ----: |  ----: |  ----: |  ----: |  ----: |
| Diabetes | 0.0115 | 0.0358 | 0.0565 | 0.0838 | 0.1074 | 0.1402 | 0.1715 | 0.2033 | 0.2548 |
| Asthma | 0.0253 | 0.0286 | 0.0373 | 0.0896 | 0.1358 | 0.1669 | 0.2097 | 0.2627 | 0.3244 |
| HIV | 0.0245 | 0.0454 | 0.0814 | 0.0922 | 0.1255 | 0.1597 | 0.1742 | 0.2013 | 0.2405 |
"
cat(tabl)
```
Quantiles of cosine similarity calculations for journals within the three subgroups.



Now, the similarities of the groups Diabetes, HIV, and Asthma versus the whole set
can be compared to one another. The tail of each distribution yields information
about how much the corpus is similar to a group, while the bulk of the distribution
yields information about how much the corpus is not similar to the group.

[](QuantDiffDiabetesAsthma.png)
[](QuantDiffDiabetesHIV.png)
[](quantDiffAsthmaHIV.png)

Estimated difference of quantiles. Calculated with WRS2 in R.

  
  
The R package WRS2 was used to calculate quantile differences between each group.
The function qcomb() was run on each of the following
pairs: diabetes-asthma, diabetes-hiv, asthma-hiv. The output values include estimated difference
for each quantile, a standard p-value, and a p.crit value. Asside from the 0 percentile estimate,
all standard p-values and p.crit values were below 0.05, while most were below 0.01.
All pairwise comparisons show a high degree of similarity in the 40th and 60th percentile range.
The most stark difference is in the 80th quantile and above. Diabetes-Asthma and Diabetes-HIV are
the most dissimilar in the upper quantiles. This indicates that the group Diabetes is more distinct
than the groups HIV and Asthma.

</br></br>

## Conclusion

The workflow described in this paper can be customized to group vectors for any of the metadata
fields in PubMed. For example, grant agency, author affiliation, year, and MESH terms are all loaded
in the beginning of the workflow. They could easily be incorporated into an analysis.

Highly skewed distributions are difficult to characterize because most estimators focus on the maximum
area of a distribution. In the case of cosine similarity in a large corpus, the distribution tail will
contain the most useful information. This workflow, and other similar workflows, allow researchers
to gather information that might not be readily apparent with a standard statistical approach.

</br></br>

## thebibliography

    \bibitem{b1} Allen, E. A., Erhardt, E. B.,  Calhoun, V. D. (2012). Data Visualization in the Neurosciences: Overcoming the Curse of Dimensionality. Neuron, 74(4), 603–608. https://doi.org/10.1016/j.neuron.2012.05.001
    \bibitem{b2} Altınel, B., Can Ganiz, M.,  Diri, B. (2015). A corpus-based semantic kernel for text classification by using meaning values of terms. Engineering Applications of Artificial Intelligence, 43, 54–66. https://doi.org/10.1016/j.engappai.2015.03.015
    \bibitem{b3} amoeba. (2016, October 4). What’s the formula for the Benjamini-Hochberg adjusted p-value? [Forum Comment]. Cross Validated. https://stats.stackexchange.com/questions/238458/whats-the-formula-for-the-benjamini-hochberg-adjusted-p-value/402217
    \bibitem{b4} Anscombe, F. J. (1973). Graphs in Statistical Analysis. The American Statistician, 27(1), 17. https://doi.org/10.2307/2682899
    \bibitem{b5} Benjamini, Y., Heller, R.,  Yekutieli, D. (2009). Selective inference in complex research. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 367(1906), 4255–4271. https://doi.org/10.1098/rsta.2009.0127
    \bibitem{b6} Benjamini, Y.,  Hochberg, Y. (1995). Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing. Journal of the Royal Statistical Society: Series B (Methodological), 57(1), 289–300. https://doi.org/10.1111/j.2517-6161.1995.tb02031.x
    \bibitem{b7} Databricks. (n.d.). Databricks spark-xml. GitHub. https://github.com/databricks/spark-xml
    \bibitem{b8} Doan, S., Yang, E. W., Tilak, S. S., Li, P. W., Zisook, D. S.,  Torii, M. (2019). Extracting health-related causality from twitter messages using natural language processing. BMC Medical Informatics and Decision Making, 19(S3), 19. https://doi.org/10.1186/s12911-019-0785-0
    \bibitem{b9} Felizardo, K. R., MacDonell, S. G., Mendes, E.,  Maldonado, J. C. (2012). A Systematic Mapping on the use of Visual Data Mining to Support the Conduct of Systematic Literature Reviews. Journal of Software, 7(2), 1. https://doi.org/10.4304/jsw.7.2.450-461
    \bibitem{b10} HARRELL, F. R. A. N. K. E.,  DAVIS, C. E. (1982). A new distribution-free quantile estimator. Biometrika, 69(3), 635–640. https://doi.org/10.1093/biomet/69.3.635
    \bibitem{b11} Kurland, O.,  Lee, L. (2009). Clusters, language models, and ad hoc information retrieval. ACM Transactions on Information Systems, 27(3), 1–39. https://doi.org/10.1145/1508850.1508851
    \bibitem{b12} Luhn, H. P. (1957). A Statistical Approach to Mechanized Encoding and Searching of Literary Information. IBM Journal of Research and Development, 1(4), 309–317. https://doi.org/10.1147/rd.14.0309
    \bibitem{b13} Mair, P.,  Wilcox, R. (2019). Robust statistical methods in R using the WRS2 package. Behavior Research Methods, 52(2), 464–488. https://doi.org/10.3758/s13428-019-01246-w
    \bibitem{b14} Manning, C. D., Raghavan, P.,  Schütze, H. (2008). Introduction to Information Retrieval [E-book]. Cambridge University Press. https://www-nlp.stanford.edu/IR-book/
    \bibitem{b15} Manning, C., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S.,  McClosky, D. (2014). The Stanford CoreNLP Natural Language Processing Toolkit. Stanford. https://nlp.stanford.edu/pubs/StanfordCoreNlp2014.pdf
    \bibitem{b16} Pennington, J., Socher, R.,  Manning, C. (2014). Glove: Global Vectors for Word Representation. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 1. https://doi.org/10.3115/v1/d14-1162
    \bibitem{b17} Rousselet, G. A., Pernet, C. R.,  Wilcox, R. R. (2017). Beyond differences in means: robust graphical methods to compare two groups in neuroscience. European Journal of Neuroscience, 46(2), 1738–1748. https://doi.org/10.1111/ejn.13610
    \bibitem{b18} Salton, G.,  Buckley, C. (1988). Term-weighting approaches in automatic text retrieval. Information Processing  Management, 24(5), 513–523. https://doi.org/10.1016/0306-4573(88)90021-0
    \bibitem{b19} Singhal, A. S. (2001). Modern Information Retrieval: A Brief Overview. IEEE. http://singhal.info/ieee2001.pdf
    \bibitem{b20} Smyth, G. S. gordon-smyth. (2012, January 1). Bioconductor Forum. Bioconductor Forum. https://support.bioconductor.org/p/49864/
    \bibitem{b21} SPARCK JONES, K. A. R. E. N. (1972). A STATISTICAL INTERPRETATION OF TERM SPECIFICITY AND ITS APPLICATION IN RETRIEVAL. Journal of Documentation, 28(1), 11–21. https://doi.org/10.1108/eb026526
    \bibitem{b22} Wilcox, R. R. (2001). Modern Insights About Pearson’s Correlation and Least Squares Regression. International Journal of Selection and Assessment, 9(1  2), 195–205. https://doi.org/10.1111/1468-2389.00172
    \bibitem{b23} Wu, H. C., Luk, R. W. P., Wong, K. F.,  Kwok, K. L. (2008). Interpreting TF-IDF term weights as making relevance decisions. ACM Transactions on Information Systems, 26(3), 1–37. https://doi.org/10.1145/1361684.1361686
    \bibitem{b23} Yekutieli, D.,  Benjamini, Y. (1999). Resampling-based false discovery rate controlling multiple test procedures for correlated test statistics. Journal of Statistical Planning and Inference, 82(1–2), 171–196. https://doi.org/10.1016/s0378-3758(99)00041-5
    \bibitem{b24} Zaharia, M., Xin, R. S., Wendell, P., Das, T., Armbrust, M., Dave, A., Meng, X., Rosen, J., Venkataraman, S., Franklin, M. J., Ghodsi, A., Gonzalez, J., Shenker, S.,  Stoica, I. (2016). Apache Spark. Communications of the ACM, 59(11), 56–65. https://doi.org/10.1145/2934664



####################### Paper



</br></br>



most similar in outgroup

```{r eval=FALSE}
ingroup_asthma_cossim <- asthma$cosine_similarity[asthma$journal_x %in% asthma$journal_asthma]
asthma$journal_x[asthma$cosine_similarity > quantile(ingroup_asthma_cossim, probs = 0.75) & !(asthma$journal_x %in% asthma$journal_asthma)]
```

```{r eval=FALSE}
ingroup_diabetes_cossim <- diabetes$cosine_similarity[diabetes$journal_x %in% diabetes$journal_diabetes]
diabetes$journal_x[diabetes$cosine_similarity > quantile(ingroup_diabetes_cossim, probs = 0.95) & !(diabetes$journal_x %in% diabetes$journal_diabetes)]
```

```{r eval=FALSE}
ingroup_hiv_cossim <- hiv$cosine_similarity[hiv$journal_x %in% hiv$journal_hiv]
hiv$journal_x[hiv$cosine_similarity > quantile(ingroup_hiv_cossim, probs = 0.85) & !(hiv$journal_x %in% hiv$journal_hiv)]
```




```{r eval=FALSE}
asthma_long <- asthma %>%
                dplyr::arrange(desc(cosine_similarity)) %>% 
                pivot_wider(
                  names_from = journal_asthma,
                  values_from = cosine_similarity
                  )


asthma_sim_matrix <- as.matrix(asthma_long[-1])
rownames(asthma_sim_matrix) <- asthma_long[[1]]

heatmap(asthma_sim_matrix)
heatmap(asthma_long[-1])
```

```{r eval=FALSE}
diabetes_long <- diabetes %>% dplyr::arrange(cosine_similarity) %>% pivot_wider( names_from = journal_diabetes, values_from = cosine_similarity)

diabetes_sim_matrix <- as.matrix(diabetes_long[-1])
rownames(diabetes_sim_matrix) <- diabetes_long[[1]]

heatmap(diabetes_sim_matrix)
```

```{r eval=FALSE}
hiv_long <- hiv %>% dplyr::arrange(cosine_similarity) %>% pivot_wider( names_from = journal_hiv, values_from = cosine_similarity)

hiv_sim_matrix <- as.matrix(hiv_long[-1])
rownames(hiv_sim_matrix) <- hiv_long[[1]]

heatmap(hiv_sim_matrix)
```



