---
title: Data Is / Data Are / Data Vis
author: Sean D McAtee
date: '2020-12-30'
slug: []
categories: []
tags: []
Description: 'A visual exploration of the singular vs plural debate'
Tags: []
Categories: []
DisableComments: yes
output:
  blogdown::html_page:
    toc: false #table of contents
    toc_float: false
---

This is not be my take on the 'Data is plural' vs 'Data is singular-ish' debate, instead this is a lighthearted visual exploration of both sides of the argument. This is also my excuse to fill a post with pretty graphs.

The data set used for the following examples is from [the open D1NAMO dataset: A multi-modal dataset for research on non-invasive type 1 diabetes management](https://www.sciencedirect.com/science/article/pii/S2352914818301059?via%3Dihub#fig4) by Fabien Dubosson et al. Data from the study is indexed in this [GitHub repo](https://github.com/irinagain/Awesome-CGM/wiki/Dubosson-(2018)). Dubosson's study followed 29 individuals, 9 of which with type-1 diabetes. Continuous glucose monitoring was done with IPro2 Professional CGM Sensor for the 9 individuals with type-1 diabetes. The 20 non-diabetic group used the Bayer Contour TX glucose meter. All 29 individuals also wore a Zephyr BioHarness 3 which tracked ECG rhythm from lead I (measuring electrical vectors from right to left across the heart), they also wore an accelerometer and a pressure sensor to measure respiration rate.


</br>  
</br>

***

## Packages Used

```{r}
library(tidyverse); library(ggplot2); library(magrittr);
library(stringi); library(hms); library(tidytext)
```


## Loading Data
```{r eval=FALSE}
workingDir <- "C:/Users/seand/OneDrive/Documents/D1NAMO/"
cohorts <- dir(workingDir)  # diabetes_subset, healthy_subset

glucose_df <- tibble()
insulin_df <- tibble()
food_nondiabetic_df <- tibble()
food_diabetic_df <- tibble()
sensor_df <- tibble()
for (cohort in cohorts) {
  participants <- dir(paste0(workingDir,cohort))
  tmp_cohort_glucose_df <- tibble()
  if(stri_cmp_eq(cohort, "diabetes_subset")){ tmp_cohort_insulin_df <- tibble() }
  if(stri_cmp_eq(cohort, "diabetes_subset")){ tmp_cohort_food_diabetic_df <- tibble()
  } else { tmp_cohort_food_nondiabetic_df <- tibble() }
  
  tmp_cohort_sensor_df <- tibble()
  for (participant in participants) {
    participant_path <- paste0(workingDir,cohort,"/",participant)
    # Gather glucose data
    glucose_path <- paste0(participant_path,"/glucose.csv")
    tmp_participant_glucose_df <- read_csv(glucose_path) %>%
      cbind(participantID = participant, cohortGroup = cohort)
    tmp_cohort_glucose_df %<>% rbind(tmp_participant_glucose_df)
    # Gather insulin data
    if(stri_cmp_eq(cohort, "diabetes_subset")){
      insulin_path <- paste0(participant_path,"/insulin.csv")
      tmp_participant_insulin_df <- read_csv(insulin_path) %>%
        cbind(participantID = participant, cohortGroup = cohort)
      tmp_cohort_insulin_df %<>% rbind(tmp_participant_insulin_df)
    }
    # Gather food data
    food_path <- paste0(participant_path,"/food.csv")
    tmp_participant_food_df <- read_csv(food_path) %>%
      cbind(participantID = participant, cohortGroup = cohort)
    if(stri_cmp_eq(cohort, "diabetes_subset")){
      tmp_cohort_food_diabetic_df %<>% rbind(tmp_participant_food_df)
    } else { tmp_cohort_food_nondiabetic_df %<>% rbind(tmp_participant_food_df) }
    # Gather sensor summary data
    times_sensor_data <- dir(paste0(participant_path,"/sensor_data"))
    sensor_summary_paths <- c()
    for (time in times_sensor_data) {
      sensor_data <- dir(paste0(participant_path,"/sensor_data/",time))
      sensor_summary <- sensor_data[which(stri_detect(sensor_data, fixed = "Summary"))]
      sensor_summary_paths <- c(sensor_summary_paths, 
                                paste0(participant_path,"/sensor_data/",
                                       time,"/",sensor_summary))
    }
    tmp_participant_sensor_df <- tibble()
    for (path in sensor_summary_paths) { tmp_participant_sensor_df %<>%
        rbind(read_csv(path)) }
    tmp_participant_sensor_df %<>% cbind(participantID = participant, cohortGroup = cohort)
    tmp_cohort_sensor_df %<>% rbind(tmp_participant_sensor_df)
  }
  glucose_df %<>% rbind(tmp_cohort_glucose_df)
  if(stri_cmp_eq(cohort, "diabetes_subset")){ insulin_df %<>% rbind(tmp_cohort_insulin_df) }
  if(stri_cmp_eq(cohort, "diabetes_subset")){
    food_diabetic_df %<>% rbind(tmp_cohort_food_diabetic_df)
  } else { food_nondiabetic_df %<>% rbind(tmp_cohort_food_nondiabetic_df) }
  sensor_df %<>% rbind(tmp_cohort_sensor_df)
}
# make date and time col for sensor_df
sensor_df %<>% mutate(date=as.Date(stri_extract(Time,regex="^(\\d{2}/\\d{2}/\\d{4})"),
                                     format = "%d/%m/%y"),
                     time=parse_hms(stri_extract(Time,regex="(\\d{2}:\\d{2}:\\d{2})"))) %>%
  select(-Time)
# food_nondiabetic_df$calories has values that should be in $description
index_cal_desc_swap <- !(stri_detect(food_nondiabetic_df$calories,regex="^\\d+$") |
                          is.na(food_nondiabetic_df$calories))
food_nondiabetic_df$description[index_cal_desc_swap] <- food_nondiabetic_df$calories[index_cal_desc_swap]
food_nondiabetic_df$calories[index_cal_desc_swap] <- NA
rm(tmp_cohort_glucose_df,tmp_participant_glucose_df,tmp_cohort_insulin_df,
   tmp_participant_insulin_df,tmp_cohort_food_diabetic_df,tmp_participant_food_df,
   tmp_cohort_food_nondiabetic_df,tmp_cohort_sensor_df,tmp_participant_sensor_df)
```

```{r include=FALSE, eval=FALSE}
write_csv(glucose_df,
          "C:/Users/seand/OneDrive/Documents/D1NAMO_combined/glucose_df.csv")
write_csv(insulin_df,
          "C:/Users/seand/OneDrive/Documents/D1NAMO_combined/insulin_df.csv")
write_csv(food_diabetic_df,
          "C:/Users/seand/OneDrive/Documents/D1NAMO_combined/food_diabetic_df.csv")
write_csv(food_nondiabetic_df,
          "C:/Users/seand/OneDrive/Documents/D1NAMO_combined/food_nondiabetic_df.csv")
write_csv(sensor_diabetic_df,
          "C:/Users/seand/OneDrive/Documents/D1NAMO_combined/sensor_df.csv")
```

```{r message=FALSE, warning=FALSE, include=FALSE}
glucose_df <- read_csv("C:/Users/seand/OneDrive/Documents/D1NAMO_combined/glucose_df.csv",
                       col_types = cols(comments = col_character()))
insulin_df <- read_csv("C:/Users/seand/OneDrive/Documents/D1NAMO_combined/insulin_df.csv",
                       col_types = cols(comment = col_character()))
food_diabetic_df <- read_csv(
  "C:/Users/seand/OneDrive/Documents/D1NAMO_combined/food_diabetic_df.csv",
  col_types=cols(quality=col_factor(
             c("Good quality", "Medium quality", "Low quality"), ordered = TRUE)))
food_nondiabetic_df <-
  read_csv("C:/Users/seand/OneDrive/Documents/D1NAMO_combined/food_nondiabetic_df.csv",
           col_types = cols(quality=col_factor(
             c("Good quality", "Medium quality", "Low quality", "No information"),
             ordered = TRUE)))
sensor_df <- read_csv("C:/Users/seand/OneDrive/Documents/D1NAMO_combined/sensor_df.csv")
```

```{r include=FALSE, message=FALSE, warning=FALSE}
# fix some junk data
if(is.na(glucose_df$glucose[8616])){ glucose_df$glucose[8616] <- 7.0 }
levels(food_nondiabetic_df$quality)[levels(
  food_nondiabetic_df$quality) == "No information"] <- NA
```


```{r ColorPalette}
colorPalette <- c('#d9a5b3', '#c6d7eb', '#1868ae', '#9ec1b6', '#9d0f40', '#e0dab7')
```


This is the `insulin_df` data table visualized.
```{r Visdat, message=FALSE, warning=FALSE, eval=TRUE}
library(visdat)
visdat::vis_dat(insulin_df)
```

While this is a single datum from `insulin_df`...
```{r Visdatum, message=FALSE, warning=FALSE, eval=TRUE}
visdat::vis_dat(insulin_df[14,3])
```
This single, numeric 'datum' on its own has no useful qualities. It may be paired with the time of measurement (`insulin_df[14,2]`) or the participant which it measured (`insulin_df[14,6]`) or even compared to some other similar datum from a different observation:
```{r}
insulin_df[24,3]
```
To what extent is this datum unit useful on its own?

This is a word cloud of most frequent words appearing in participants' meal descriptions. They are grouped by cohort: diabetic and non-diabetic.
```{r Food_Wordcloud, message=FALSE, warning=FALSE, eval=TRUE}
library(wordcloud2)
# https://cran.r-project.org/web/packages/wordcloud2/vignettes/wordcloud.html

data("stop_words")

topFoods <- function(df, color1, color2){
  wordFreq <- unnest_tokens(tbl = df, output = word, input = description) %>%
    anti_join(y = stop_words, by = "word") %>% 
    filter(stri_detect(word, regex = "^(\\D)")) %>% 
    count(word, sort = TRUE, name = "freq")
  wordcloud2(wordFreq, color = c(rep(color1, 10),rep(color2, nrow(wordFreq)-10)))
}
topFoods(food_diabetic_df, colorPalette[3], colorPalette[6])
topFoods(food_nondiabetic_df, colorPalette[5], colorPalette[4])
```

## LINGVA LATINA
Speaking of words, one may argue to use data/datum over data/data by citing Latin grammar rules for second-declension neuter nouns. Using data/datum in the [nominative](https://classics.osu.edu/Undergraduate-Studies/Latin-Program/Grammar/Cases/nominative-case) or [accusative](https://classics.osu.edu/Undergraduate-Studies/Latin-Program/Grammar/Cases/accusative-case) case would make [Horace proud](https://www.poetryintranslation.com/PITBR/Latin/HoraceSatiresBkISatX.php#anchor_Toc98155847) (or [vocative](https://classics.osu.edu/Undergraduate-Studies/Latin-Program/Grammar/Cases/latin-case), assuming you talk to your data). But what of the [genative](https://classics.osu.edu/Undergraduate-Studies/Latin-Program/Grammar/Cases/genitive-case) or the [ablative](https://classics.osu.edu/Undergraduate-Studies/Latin-Program/Grammar/Cases/ablative-case-latin) cases? Is this rule the same for all of my datī or just one of my datōrum? Does one also gather information from datō or a single datīs? Is this an exaggeration? I prefer to leave no hair unsplit, if it is my vocation to split them.

The Latin argument was a fun way to reminisce back to my high school Latin classes, however I think the most damning argument lies in the English language. Specifically 'Academic English', the Dr. Frankenstein of ghastly words. Consider [eigenvalue](https://www.maa.org/press/periodicals/convergence/math-origins-eigenvectors-and-eigenvalues), [neurotransmitter](https://en.wiktionary.org/wiki/neurotransmitter), [Sociology](https://www.thefreedictionary.com/words-containing-ology), [octopus](https://www.merriam-webster.com/words-at-play/the-many-plurals-of-octopus-octopi-octopuses-octopodes) and [many more](https://en.wikipedia.org/wiki/Hybrid_word). As a word, data has been claimed by English. As English speakers, it is up to us to use data/datum however we please until a consensus is reached.

But what do individual words really mean? Out of the context of a sentence, do they tell use anything?
Term Frequency (TF) and Inverse Document Frequency (IDF) are simple statistics that help illuminate which words are most specific to certain documents. TF is straight forward, the total number of times a term appears divided by the number of unique terms. IDF is the number of documents divided by the number of documents in which each term appears, usually this proportion is log or ln scaled. For example, if we are looking at 5 essays and we want to find the IDF of "potato", and we know that the term "potato" appears in 3 of the 5 essays:
$$IDF("potato") = ln(numberOfDocs / numberOfDocsWithPotato) = ln(5/3)$$

Once each terms' TF and IDF are calculated, they are multiplied together to make a weight or score of how specific each term is, compared to the rest of the terms. A term like "potato" is rather specific, so it should have a higher TF-IDF than the term "and".

Rather than grouping IDF by 'document' I grouped the words in participants' meal description by the `quality` of the meal assigned by a dietitian.
```{r tfidf_Food_Per_Cohort, message=FALSE, warning=FALSE, eval=TRUE}
# TF-IDF
tfidf <- function(df, group){
  unnest_tokens(df, word, description) %>%
  anti_join(stop_words, by = "word") %>%
  filter(stri_detect(word, regex = "^(\\D)")) %>% 
  count(word, across({{ group }}), name = "n") %>%
  bind_tf_idf(word, {{ group }}, n)
}
tfidf(food_diabetic_df, "quality")
```

The four histograms below show relationships between TF, IDF, and TF-IDF. Each histogram is colored by the upper and lower 50% quantiles of TF (green, blue) and IDF (pink, yellow).

```{r Hist_Food_Per_Cohort, message=FALSE, warning=FALSE, eval=TRUE}
# hist comparison of n, tf, idf, tf-idf
tfidf_quality <- tfidf(food_diabetic_df, "quality")
tfidf_quality %<>% mutate(
  tfQuantile = ifelse(tf > quantile(tf,probs = 0.5,na.rm = TRUE,names = FALSE),
                    "highQuant","lowQuant"),
  idfQuantile = ifelse(idf > quantile(idf,probs = 0.5,na.rm = TRUE,names = FALSE),
                    "highQuant","lowQuant")
  )

tfidf_hist <- function(df, x, fill, binwidth, color1, color2){
  df %>% ggplot( aes(x = {{ x }}, fill = {{ fill }}) ) +
    geom_histogram(binwidth = binwidth, color = 'white') +
    scale_fill_manual(values = c(color1, color2))
}
```

This shows term frequency overylayed by the IDF upper and lower quantiles. The majority of TF is towards 0.00 becasue most terms appear infrequently. IDF upper and lower quantiles are spread through the distribution of TF.
```{r tf_idfQuantile_Food_Per_Cohort, message=FALSE, warning=FALSE, eval=TRUE}
tfidf_hist(tfidf_quality, `tf`, `idfQuantile`, 0.005, colorPalette[1], colorPalette[6])
```

This shows IDF overlayed by TF upper and lower quantiles. There are three IDF spikes since each term can only appear in one, two, or three `quality` groups.
$ln(3/3)$ or $ln(3/2)$ or $ln(3/1)$
Most terms appear in only one document, with a majority of these terms in the lower TF quantile.
```{r idf_tfQuantile_Food_Per_Cohort, message=FALSE, warning=FALSE, eval=TRUE}
tfidf_hist(tfidf_quality, `idf`, `tfQuantile`, 0.08, colorPalette[4], colorPalette[2])
```

This shows TF-IDF overlayed by TF upper and lower quantiles. Few terms have TF-IDF above 0.02 and none of the lower quantile TF terms have TF-IDF scores above 0.01
```{r tfidf_tfQuantile_Food_Per_Cohort, message=FALSE, warning=FALSE, eval=TRUE}
tfidf_hist(tfidf_quality, `tf_idf`, `tfQuantile`, 0.002, colorPalette[4], colorPalette[2])
```

This shows TF-IDF overlayed by IDF upper and lower quantiles. Upper quantile IDF terms are shifted above an TF-IDF score of 0.005. There are still some lower quantile IDF terms with the highest TF-IDF scores above 0.2, showing that IDF alone would lose some terms that TF-IDF selects.
```{r tfidf_idfQuantile_Food_Per_Cohort, message=FALSE, warning=FALSE, eval=TRUE}
tfidf_hist(tfidf_quality, `tf_idf`, `idfQuantile`, 0.002, colorPalette[1], colorPalette[6])
```


Here is a treemap showing the top TF-IDF terms that are explored above. They are grouped by diabetic and non-diabetic cohorts.
```{r Treemap_Food_Per_Cohort, message=FALSE, warning=FALSE, eval=TRUE}
library(treemap)
# tree map or mosaic map
mosaic <- function(df, group, plotTitle){
 df %>% filter(n > 3, tf_idf > 0) %>%
  arrange(group) %>% 
  treemap::treemap(index = c(group, "word"),vSize = "tf_idf",vColor = group,
                   type = "categorical",title = plotTitle,fontsize.labels = c(0, 10),
                   fontfamily.labels = "serif",
                   palette = c(colorPalette[4],colorPalette[2],colorPalette[1]),
                   align.labels = c("center", "center"),border.lwds = 0
                   )
}
food_diabetic_tfidf<- tfidf(food_diabetic_df, "quality")
food_nondiabetic_tfidf<- tfidf(food_nondiabetic_df, "quality")
```

Diabetic Cohort
```{r Treemap_Diabetic_Food_Per_Cohort, message=FALSE, warning=FALSE, eval=TRUE}
mosaic(food_diabetic_tfidf, "quality", "TF-IDF")
```

Non Diabetic Cohort
```{r Treemap_NonDiabetic_Food_Per_Cohort, message=FALSE, warning=FALSE, eval=TRUE}
mosaic(food_nondiabetic_tfidf, "quality", "TF-IDF")
```

There were only 9 diabetic participants and 20 non-diabetic participants. Most of the grouped terms make sense, cookies - low quality, strawberry - medium quality, chapeignon - good quality? I guess it is important to note that this study took place in the Swiss town Vevey.

This shows the percent of meals that are high, medium, or low quality grouped by cohort. The diabetic participants have type-1 diabetes, which likely influences the amount of low quality food they eat.
```{r Stacked_Bar_Food_Quality_Cohort, fig.asp=.4, message=FALSE, warning=FALSE, eval=TRUE}
# amount of meals for each quality, per cohort
foodQualityMatrix <- matrix(c(count(food_nondiabetic_df, quality)$n,
                              count(food_diabetic_df, quality)$n), ncol = 2)
colnames(foodQualityMatrix) <- c("nondiabetic", "diabetic")

# arrange good, med, low
foodQualityMatrix <- rbind(foodQualityMatrix[1,],foodQualityMatrix[3,],foodQualityMatrix[2,])
rownames(foodQualityMatrix) <- c("Good quality", "Medium quality", "Low quality")
par(mar=c(5,6,2,1))

apply(foodQualityMatrix, 2, function(x){x*100/sum(x)}) %>%
  barplot(horiz = TRUE,col = c(colorPalette[4],colorPalette[2],colorPalette[1]),
    legend.text = TRUE,args.legend = list(x = "topleft", inset=c(0.10,-0.18),
                                          ncol = 4, bty='n', xpd = TRUE),
    las = 1,border = 'white',xlab = 'Percent of Meals by Quality'
          )
```

</br>  
</br>

***

## Data is like water

Returning to data/datum/datīs.
When I think of data, I think of distributions. Much of the data that I am interested in is big, large, or massive. When data is the size of a lake, I am not that interested in one particular datum molecule. The sensor data from this study has `r nrow(sensor_df)*ncol(sensor_df)` mols of data, or data points, or datum. Included in the sensor data are `r sum(!is.na(sensor_df$HR))` heart rate and breathing rate measurements. The continuous glucose monitor (CGM) data is `r nrow(glucose_df)` rows long. Only the diabetic cohort had CGM monitors.

This shows the distributions of Continuous Glucose Monitor (CGM) Measurements for all 9 diabetic participants.
```{r Violen_Glucose_Cohort, fig.asp=0.35, message=FALSE, warning=FALSE, eval=TRUE}
glucose_df %>% filter(type == "cgm") %>% ggplot(aes(x=participantID, y=glucose)) +
  geom_violin(trim = FALSE, fill=colorPalette[2], color=colorPalette[3]) +
  geom_boxplot(width=0.06, fill=colorPalette[1]) +
  labs(x = "participantID", y = "Blood Glucose [mmol/L]") +
  ggtitle("Participant Distributions of CGM Measurements") +
  geom_hline(yintercept=11.1, linetype='dashed', color=colorPalette[5], size=0.6) +
  annotate("text", x="009", y=11.1, label="High", color = colorPalette[5], vjust=-0.5) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

This shows the distribution of participant 006 CGM, heart rate, and breathing rate on 2014-10-02.
```{r Ridgeline_CGM, fig.asp=0.5, results='hold', message=FALSE, warning=FALSE, eval=TRUE}
library(ggridges)
# https://cran.r-project.org/web/packages/ggridges/vignettes/introduction.html
glucose_df %>%
  filter(type == "cgm", participantID == "006", date == unique(date)[2]) %>%
  mutate(time=stri_extract(as.character(time),regex="^(\\d{2})")) %>% 
  ggplot(aes(x=glucose, y=time, fill=stat(x))) +
  geom_density_ridges_gradient(scale=1.3, rel_min_height=0.01) +
  scale_fill_continuous(name="Glucose", low=colorPalette[1], high=colorPalette[5]) +
  labs(x="Blood Glucose [mmol/L]", y="Hour") +
  ggtitle('Participant 006\nHourly CGM Distribution\n2014-10-02') +
  geom_vline(xintercept=11.1, linetype='dashed', color=colorPalette[5], size=0.6) +
  annotate("text", x=11.1, y="06", label="High", color=colorPalette[5], hjust=-0.4) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Heart Rate
sensor_df %>%
  select(HR, BR, Activity, participantID, cohortGroup, date, time) %>%
  mutate(time = stri_extract(as.character(time), regex = "^(\\d{2})")) %>%
  filter(participantID == "006", cohortGroup == "diabetes_subset",
         date == unique(date)[2], HR > 0, BR > 0) %>% 
  ggplot(aes(x=HR, y=time, fill=stat(x))) +
  geom_density_ridges_gradient(scale=1.3, rel_min_height=0.01) +
  scale_fill_continuous(name="Heart Rate", low=colorPalette[2], high=colorPalette[4]) +
  labs(x="Heart Rate [bpm]", y="Hour") +
  ggtitle("Participant 006\nHourly Heart Rate Distribution\n2014-10-02") +
  theme_minimal()

# Breathing Rate
sensor_df %>%
  select(HR, BR, Activity, participantID, cohortGroup, date, time) %>%
  mutate(time = stri_extract(as.character(time), regex = "^(\\d{2})")) %>%
  filter(participantID == "006", cohortGroup == "diabetes_subset",
         date == unique(date)[2], HR > 0, BR > 0) %>% 
  ggplot(aes(x=BR, y=time, fill=stat(x))) +
  geom_density_ridges_gradient(scale=1.3, rel_min_height=0.01) +
  scale_fill_continuous(name="Breathing Rate", low=colorPalette[6], high=colorPalette[3]) +
  labs(x="Breathing Rate [breaths/min]", y="Hour") +
  ggtitle("Participant 006\nHourly Breathing Rate Distribution\n2014-10-02") +
  theme_minimal()
```

While exploring time series, here is an uncommon type of graph: the radar graph. Radar graphs, aka spider graphs, are used in some areas of Psychology and Medicine with categorical data. Some individuals seem to like them since they can display multiple correlated categories in a small space. I personally think that there are better options to display categorical data, however radar graphs could become useful with continuous cyclical or seasonal data. Here is an example of the CGM of the same participant (006) on 2014-10-02.
```{r Radar_Single_Participant_CGM, message=FALSE, warning=FALSE, eval=TRUE}
library(fmsb)
# https://cran.r-project.org/web/packages/fmsb/fmsb.pdf
# radar cgm for one individual
glucose_df_wide <- 
  filter(glucose_df, type == "cgm", participantID == "006", date == unique(date)[2]) %>%
  mutate(time = stri_extract(as.character(time),regex="^(\\d{2})")) %>%
  group_by(time) %>% 
  summarise(glucose = mean(glucose)) %>%
  pivot_wider(names_from = time, values_from = glucose)

rbind(
  rep(16,ncol(glucose_df_wide)),
  rep(4,ncol(glucose_df_wide)),
  glucose_df_wide[,order(ncol(glucose_df_wide):1)]
) %>% radarchart(axistype=1, seg=3, plwd=1, centerzero=FALSE, cglcol=colorPalette[1], cglty=1,
                 axislabcol=colorPalette[5], caxislabels=seq(4,16,4), vlcex=0.8,
                 title = "Participant 006\nHourly Mean Glucose\n2014-10-02"
                 )
```
Few R packages exist for generating spider graphs, unfortunately I could not find a package that allows overlapping lines. With overlapping lines these graphs could become useful to compare each cycle or season of timeseries data.


</br>  
</br>

***

## Conclusion

If you were not convinced by my hair splitting Latin argument, or by my Frankenstein argument, or by my 'data is like water' argument, then I hope that you at least enjoyed my data vis.